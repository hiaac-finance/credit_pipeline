{"cells":[{"cell_type":"markdown","metadata":{"id":"AOPCGcD-K-B0"},"source":["# Experiments with Home Credit"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"GS4_XnYslJ3J"},"outputs":[{"name":"stderr","output_type":"stream","text":["UsageError: Line magic function `%` not found.\n"]}],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neural_network import MLPClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.metrics import roc_auc_score, balanced_accuracy_score, accuracy_score, precision_score, recall_score, f1_score\n","import pickle as pkl\n","\n","import credit_pipeline.data_exploration as dex\n","from credit_pipeline.training import *\n","\n","% load_ext autoreload\n","% autoreload 2"]},{"cell_type":"markdown","metadata":{},"source":["## Loading and Cleaning"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["seed_number = 0"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["path = \"../data/HomeCredit/\"\n","df = dex.read_csv_encoded(path, 'application_train.csv')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["['COMMONAREA_MEDI',\n"," 'COMMONAREA_AVG',\n"," 'COMMONAREA_MODE',\n"," 'NONLIVINGAPARTMENTS_MODE',\n"," 'NONLIVINGAPARTMENTS_AVG',\n"," 'NONLIVINGAPARTMENTS_MEDI',\n"," 'FONDKAPREMONT_MODE',\n"," 'LIVINGAPARTMENTS_MODE',\n"," 'LIVINGAPARTMENTS_AVG',\n"," 'LIVINGAPARTMENTS_MEDI',\n"," 'FLOORSMIN_AVG',\n"," 'FLOORSMIN_MODE',\n"," 'FLOORSMIN_MEDI',\n"," 'YEARS_BUILD_MEDI',\n"," 'YEARS_BUILD_MODE',\n"," 'YEARS_BUILD_AVG',\n"," 'OWN_CAR_AGE',\n"," 'LANDAREA_MEDI',\n"," 'LANDAREA_MODE',\n"," 'LANDAREA_AVG',\n"," 'BASEMENTAREA_MEDI',\n"," 'BASEMENTAREA_AVG',\n"," 'BASEMENTAREA_MODE',\n"," 'EXT_SOURCE_1',\n"," 'NONLIVINGAREA_MODE',\n"," 'NONLIVINGAREA_AVG',\n"," 'NONLIVINGAREA_MEDI',\n"," 'ELEVATORS_MEDI',\n"," 'ELEVATORS_AVG',\n"," 'ELEVATORS_MODE',\n"," 'WALLSMATERIAL_MODE',\n"," 'APARTMENTS_MEDI',\n"," 'APARTMENTS_AVG',\n"," 'APARTMENTS_MODE',\n"," 'ENTRANCES_MEDI',\n"," 'ENTRANCES_AVG',\n"," 'ENTRANCES_MODE',\n"," 'LIVINGAREA_AVG',\n"," 'LIVINGAREA_MODE',\n"," 'LIVINGAREA_MEDI',\n"," 'HOUSETYPE_MODE']"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["columns_to_drop = dex.check_missing(df, 50,  False)\n","columns_to_drop"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["df = df.drop(columns_to_drop, axis=1)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["['NAME_CONTRACT_TYPE',\n"," 'CODE_GENDER',\n"," 'FLAG_OWN_CAR',\n"," 'FLAG_OWN_REALTY',\n"," 'NAME_TYPE_SUITE',\n"," 'NAME_INCOME_TYPE',\n"," 'NAME_EDUCATION_TYPE',\n"," 'NAME_FAMILY_STATUS',\n"," 'NAME_HOUSING_TYPE',\n"," 'OCCUPATION_TYPE',\n"," 'WEEKDAY_APPR_PROCESS_START',\n"," 'ORGANIZATION_TYPE',\n"," 'EMERGENCYSTATE_MODE']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df_cols = df.columns.to_list()\n","obj_cols = dex.list_by_type(df, ['O'])\n","obj_cols"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def days_to_years(dataframe, col_name):\n","        \"\"\"\n","        Converts values from string to numeric.\n","        Uses the map function to convert the information on days employed to years employed\n","        \"\"\"\n","        df_name = dataframe.copy()\n","\n","        if col_name in df.columns:\n","            #Converts values from string to numeric.\n","            df_name[col_name] = pd.to_numeric(df_name[col_name], errors='coerce')\n","\n","            #drops null values on the column\n","            df_name = df_name.dropna(subset=[col_name])\n","\n","            #Use the map function to convert the information on days employed to years employed\n","            year = df_name.loc[:, col_name].map(lambda x: int(abs(x / 365)), na_action=None)\n","            df_name['YEARS'+col_name[4:]] = year\n","\n","            #drops the column\n","            df_name = df_name.drop(col_name, axis=1)\n","\n","        return df_name\n","\n","\n","df = days_to_years(df, \"DAYS_EMPLOYED\")\n","df = days_to_years(df, 'DAYS_BIRTH')"]},{"cell_type":"markdown","metadata":{},"source":["## Training Basic Models"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"chM4tJtz9V6e"},"outputs":[],"source":["X_acp = df.iloc[:, (df.columns != \"TARGET\") & (df.columns != \"SK_ID_CURR\")]\n","y_acp = df[\"TARGET\"]"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"9blMaysuPui4"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(\n","    X_acp, \n","    y_acp, \n","    test_size = 0.2, \n","    random_state=seed_number, \n","    stratify=y_acp\n",")\n","X_train, X_val, y_train, y_val = train_test_split(\n","    X_train, \n","    y_train, \n","    test_size = 0.2, \n","    random_state=seed_number, \n","    stratify=y_train\n",")"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1695152363955,"user":{"displayName":"Athyrson Machado Ribeiro","userId":"03264544371961652552"},"user_tz":180},"id":"FP4M_FYobzNM","outputId":"c6968a46-e41f-40bd-9bfe-50021697f066"},"outputs":[],"source":["classifiers = {\n","    \"Logistic Regression\": LogisticRegression,\n","    \"Random Forest\": RandomForestClassifier,\n","    \"LightGBM\": LGBMClassifier,\n","    \"MLPC\" : MLPClassifier,\n","}"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"Gf0vyh7ec9vi"},"outputs":[],"source":["param_spaces = {\n","    \"LogisticRegression\": {\n","        'C': {'low': 0.001, 'high': 10, 'log': True, 'type':'float'},\n","        'max_iter': {'low': 1000, 'high': 1000, 'step':1, 'type':'int'},\n","        'penalty': {'choices': ['l2'], 'type':'categorical'}\n","    },\n","    \"RandomForestClassifier\": {\n","        'n_estimators': {'low':10, 'high':150, 'step':20, 'type':'int'},\n","        'max_depth': {'low':2, 'high':10, 'type':'int'},\n","        'criterion': {'choices':['gini', 'entropy'], 'type':'categorical'},\n","        'min_samples_leaf' : {\"low\" : 1, \"hight\" : 50, \"step\" : 5, 'type':'int'},\n","        \"max_features\" : {\"low\" : 0.1, \"hight\" : 1.0, \"type\" : \"float\"},\n","    },\n","    \"LGBMClassifier\": {\n","        'learning_rate': {'low': 0.01, 'high': 1.0, 'type': 'float', 'log': True},\n","        'max_depth': {'low': 2, 'high': 10, 'type': 'int'},\n","        'min_child_samples': {'low': 1, 'high': 50, 'step': 5, 'type': 'int'},\n","        'colsample_bytree': {'low': 0.1, 'high': 1.0, 'type': 'float'},\n","        'reg_alpha': {'low': 0.0, 'high': 1.0, 'type': 'float'},\n","        'reg_lambda': {'low': 0.0, 'high': 1.0, 'type': 'float'},\n","        'n_estimators': {'low': 10, 'high': 100, 'step': 10, 'type': 'int'},\n","        \n","    },\n","    \"MLPClassifier\": {\n","        \"hidden_layer_sizes\" : {\"coices\" : [\n","            [128, 256, 128],\n","            [128, 256, 256, 128],\n","            [128, 256, 256, 128, 64]\n","        ], 'type':'categorical'},\n","        \"alpha\" : {'low': 0.0001, 'high': 0.01, 'type': 'float', 'log': True},\n","        \"learning_rate\" : {'choices': ['constant', 'invscaling', 'adaptive'], 'type':'categorical'},\n","        \"learning_rate_init\" : {'low': 0.001, 'high': 0.1, 'type': 'float', 'log': True},\n","        \"early_stopping\" : {'choices': [True, False], 'type':'categorical'},\n","    }\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["study_logistic = optimize_model(LogisticRegression, param_spaces[\"LogisticRegression\"], X_train, y_train, X_val , y_val, n_trials=100)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Score for Logistic Regression:  0.7412956303231619\n","{'C': 8.16453047345026, 'max_iter': 1000, 'penalty': 'l2'}\n"]}],"source":["print(\"Score for Logistic Regression: \", study_logistic.best_value)\n","print(study_logistic.best_params)\n","pkl.dump(study_logistic, open(\"study_logistic.pkl\", \"wb\"))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["study_rf = optimize_model(RandomForestClassifier, param_spaces[\"RandomForestClassifier\"], X_train, y_train, X_val , y_val, n_trials=100)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Score for Random Forest:  0.7394031490386275\n","{'n_estimators': 146, 'max_depth': 10, 'criterion': 'entropy'}\n"]}],"source":["print(\"Score for Random Forest: \", study_rf.best_value)\n","print(study_rf.best_params)\n","pkl.dump(study_rf, open(\"study_rf.pkl\", \"wb\"))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["study_lgbm = optimize_model(LGBMClassifier, param_spaces[\"LGBMClassifier\"], X_train, y_train, X_val , y_val, n_trials=100)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Score for LGBM:  0.7538204864963433\n","{'learning_rate': 0.16993343789723322, 'num_leaves': 15, 'max_depth': 4, 'min_child_samples': 40, 'subsample': 0.40547037083183, 'colsample_bytree': 0.9811676942834585, 'reg_alpha': 0.26067703219886407, 'reg_lambda': 0.9849015614655063, 'verbose': -1}\n"]}],"source":["print(\"Score for LGBM: \", study_lgbm.best_value)\n","print(study_lgbm.best_params)\n","pkl.dump(study_lgbm, open(\"study_lgbm.pkl\", \"wb\"))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["study_mlp = optimize_model(MLPClassifier, param_spaces[\"MLPClassifier\"], X_train, y_train, X_val , y_val, n_trials=100)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Score for MLP:  0.7447455369100395\n","{'hidden_layer_sizes': 8, 'alpha': 0.0009663190086858645, 'learning_rate': 'adaptive', 'learning_rate_init': 0.0014289217221067222}\n"]}],"source":["print(\"Score for MLP: \", study_mlp.best_value)\n","print(study_mlp.best_params)\n","pkl.dump(study_mlp, open(\"study_mlp.pkl\", \"wb\"))"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Score for Logistic Regression:  0.7412956303231619\n","Score for Random Forest:  0.7394031490386275\n","Score for LGBM:  0.7538204864963433\n","Score for MLP:  0.7447455369100395\n"]}],"source":["print(\"Score for Logistic Regression: \", study_logistic.best_value)\n","print(\"Score for Random Forest: \", study_rf.best_value)\n","print(\"Score for LGBM: \", study_lgbm.best_value)\n","print(\"Score for MLP: \", study_mlp.best_value)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OVj_gguE5Iy7"},"outputs":[],"source":["def get_metrics(name_model_dict, X, y, threshold = 0.5):\n","    models_dict = {}\n","    for name, model in name_model_dict.items():\n","        if type(model) == list:\n","            y_prob = model[0].predict_proba(X)[:,1]\n","            threshold_model = model[1]\n","            y_pred = (y_prob >= threshold_model).astype('int')\n","        else:\n","            y_prob = model.predict_proba(X)[:,1]\n","            y_pred = (y_prob >= threshold).astype('int')\n","\n","        models_dict[name] = (y_pred, y_prob)\n","\n","    def get_metrics_df(models_dict, y_true,):\n","        metrics_dict = {\n","            \"Overall AUC\": (\n","                lambda x: roc_auc_score(y_true, x), False),\n","            \"------\": (lambda x: \"\", True),\n","            \"Balanced Accuracy\": (\n","                lambda x: balanced_accuracy_score(y_true, x), True),\n","            \"Accuracy\": (\n","                lambda x: accuracy_score(y_true, x), True),\n","            \"Precision\": (\n","                lambda x: precision_score(y_true, x, zero_division=0), True),\n","            \"Recall\": (\n","                lambda x: recall_score(y_true, x), True),\n","            \"F1\": (\n","                lambda x: f1_score(y_true, x), True),\n","        }\n","        df_dict = {}\n","        for metric_name, (metric_func, use_preds) in metrics_dict.items():\n","            df_dict[metric_name] = [metric_func(preds) if use_preds else metric_func(scores)\n","                                    for model_name, (preds, scores) in models_dict.items()]\n","        return pd.DataFrame.from_dict(df_dict, orient=\"index\", columns=models_dict.keys())\n","\n","    return get_metrics_df(models_dict, y)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import roc_curve, brier_score_loss"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_opt_pred(y_true, y_score):\n","    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n","    opt_threshold = thresholds[np.argmax(tpr - fpr)]\n","    y_pred = (y_score >= opt_threshold).astype('int')\n","    return y_pred\n","\n","def get_metrics(y_true, y_score):\n","    y_pred = get_opt_pred(y_true, y_score)\n","    \n","    metrics_dict = {\n","        \"roc_auc\" : roc_auc_score(y_true, y_score),\n","        \"balanced_accuracy\" : balanced_accuracy_score(y_true, y_pred),\n","        \"accuracy\" : accuracy_score(y_true, y_pred),\n","        \"precision\" : precision_score(y_true, y_pred, zero_division=0),\n","        \"recall\" : recall_score(y_true, y_pred),\n","        \"f1\" : f1_score(y_true, y_pred),\n","        \"brier_score\" : brier_score_loss(y_true, y_score),\n","    }\n","    return metrics_dict\n","\n","def get_fairness_metrics(y_true, y_score, sensitive_attr):\n","    # sensitive attribute must be 0 or 1\n","    y_pred = get_opt_pred(y_true, y_score)\n","    # statistical disparity\n","    p_y1_z1 = np.mean(y_pred[sensitive_attr == 1])\n","    p_y1_z0 = np.mean(y_pred[sensitive_attr == 0])\n","    spd = p_y1_z1 - p_y1_z0\n","\n","    # equalized odds\n","    tpr_z1 = recall_score(y_true[sensitive_attr == 1], y_pred[sensitive_attr == 1])\n","    tpr_z0 = recall_score(y_true[sensitive_attr == 0], y_pred[sensitive_attr == 0])\n","    eod = tpr_z1 - tpr_z0\n","\n","    # geometric mean of accuracies\n","    accuracy_z1 = accuracy_score(y_true[sensitive_attr == 1], y_pred[sensitive_attr == 1])\n","    accuracy_z0 = accuracy_score(y_true[sensitive_attr == 0], y_pred[sensitive_attr == 0])\n","    gma = np.sqrt(accuracy_z1 * accuracy_z0)\n","\n","    metrics_dict = {\n","        \"statistical_disparity\" : spd,\n","        \"equalized_odds\" : eod,\n","        \"geometric_mean_accuracy\" : gma,\n","    }\n","    return metrics_dict\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_metrics(name_model_dict, X, y, threshold = 0.5):\n","    models_dict = {}\n","    for name, model in name_model_dict.items():\n","        if type(model) == list:\n","            y_prob = model[0].predict_proba(X)[:,1]\n","            threshold_model = model[1]\n","            y_pred = (y_prob >= threshold_model).astype('int')\n","        else:\n","            y_prob = model.predict_proba(X)[:,1]\n","            y_pred = (y_prob >= threshold).astype('int')\n","\n","        models_dict[name] = (y_pred, y_prob)\n","\n","    def get_metrics_df(models_dict, y_true,):\n","        metrics_dict = {\n","            \"Overall AUC\": (\n","                lambda x: roc_auc_score(y_true, x), False),\n","            \"------\": (lambda x: \"\", True),\n","            \"Balanced Accuracy\": (\n","                lambda x: balanced_accuracy_score(y_true, x), True),\n","            \"Accuracy\": (\n","                lambda x: accuracy_score(y_true, x), True),\n","            \"Precision\": (\n","                lambda x: precision_score(y_true, x, zero_division=0), True),\n","            \"Recall\": (\n","                lambda x: recall_score(y_true, x), True),\n","            \"F1\": (\n","                lambda x: f1_score(y_true, x), True),\n","        }\n","        df_dict = {}\n","        for metric_name, (metric_func, use_preds) in metrics_dict.items():\n","            df_dict[metric_name] = [metric_func(preds) if use_preds else metric_func(scores)\n","                                    for model_name, (preds, scores) in models_dict.items()]\n","        return pd.DataFrame.from_dict(df_dict, orient=\"index\", columns=models_dict.keys())\n","\n","    return get_metrics_df(models_dict, y)"]},{"cell_type":"markdown","metadata":{"id":"eb5LLRRksbLS"},"source":["**TODO**\n","\n","*   Add easy way to include default parameters in optuna\n","*   Warnings on pipeline given numeric unique number of values\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1ZMaWNR4MI5pyjbCLwUSkh7B_HshPUop8","timestamp":1694628479812}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"}},"nbformat":4,"nbformat_minor":0}
