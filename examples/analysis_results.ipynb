{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 09:21:28.296509: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-04 09:21:28.330551: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-04 09:21:28.330568: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-04 09:21:28.331508: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-04 09:21:28.336949: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-04 09:21:28.338368: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-04 09:21:29.326577: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import to_hex\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import ticker\n",
    "import joblib\n",
    "from glob import glob\n",
    "import sys\n",
    "from credit_pipeline import training, evaluate\n",
    "\n",
    "sys.path.append(\"../scripts\")\n",
    "from experiments import load_split, PROTECTED_ATTRIBUTES\n",
    "\n",
    "# small fix to be able to load models\n",
    "from credit_pipeline.training import EBE\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_table(metrics):\n",
    "    metrics_mean = metrics.groupby(\"model\").apply(lambda x : x.abs().mean())\n",
    "    metrics_std = metrics.groupby(\"model\").apply(lambda x : x.abs().std())\n",
    "    for col in metrics_mean.columns:\n",
    "        metrics_mean[col] = (\n",
    "            metrics_mean[col].round(3).astype(str)\n",
    "            + \" ± \"\n",
    "            + metrics_std[col].round(3).astype(str)\n",
    "        )\n",
    "    #metrics_mean = metrics_mean.drop(columns=metrics_std.columns)\n",
    "    metrics_mean = metrics_mean.reset_index()\n",
    "    return metrics_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_credit_experiment_perf(dataset_name, seed = 0):\n",
    "    \"\"\"Function that summarizes the results of the credit models experiment.\n",
    "    It will print the mean and standard deviation of metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    path = \"../results/credit_models_unaware\"\n",
    "    metrics_folds_val = []\n",
    "    metrics_folds_test = []\n",
    "    for fold in range(10):\n",
    "        model_dict = {}\n",
    "        X_train, A_train, Y_train, X_val, A_val, Y_val, X_test, A_test, Y_test = load_split(\n",
    "            dataset_name, fold, seed, unaware = True\n",
    "        )\n",
    "\n",
    "\n",
    "        models_files = glob(f\"{path}/{dataset_name}/{fold}/*.pkl\")\n",
    "        # remove the ones that are not models\n",
    "        models_files = [file for file in models_files if \"study\" not in file]\n",
    "\n",
    "        for file in models_files:\n",
    "            model = joblib.load(file)\n",
    "            model_name = file.split(\"/\")[-1].split(\".\")[0]\n",
    "            Y_train_pred = model.predict_proba(X_train)[:, 1]\n",
    "            threshold = training.ks_threshold(Y_train, Y_train_pred)\n",
    "            model_dict[model_name] = [model, threshold]\n",
    "\n",
    "        metrics_folds_val.append(evaluate.get_metrics(model_dict, X_val, Y_val))\n",
    "        metrics_folds_test.append(evaluate.get_metrics(model_dict, X_test, Y_test))\n",
    "\n",
    "    metrics_val = pd.concat(metrics_folds_val)\n",
    "    metrics_test = pd.concat(metrics_folds_test)\n",
    "\n",
    "    return metrics_val, metrics_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = {}\n",
    "for dataset in [\"german\", \"taiwan\", \"homecredit\"]:\n",
    "    _, t = summarize_credit_experiment_perf(dataset, 0)\n",
    "    test_metrics[dataset] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german\n",
      "                    model            AUC    Brier Score Balanced Accuracy  \\\n",
      "0          LGBMClassifier    0.71 ± 0.02  0.225 ± 0.027     0.656 ± 0.033   \n",
      "1      LogisticRegression  0.761 ± 0.008  0.195 ± 0.004     0.701 ± 0.014   \n",
      "2           MLPClassifier   0.755 ± 0.03    0.2 ± 0.015     0.696 ± 0.033   \n",
      "3  RandomForestClassifier  0.748 ± 0.017  0.208 ± 0.011     0.688 ± 0.025   \n",
      "\n",
      "        Accuracy      Precision         Recall             F1  \n",
      "0  0.694 ± 0.022  0.596 ± 0.061  0.521 ± 0.157  0.536 ± 0.079  \n",
      "1   0.71 ± 0.032   0.59 ± 0.053  0.669 ± 0.089   0.621 ± 0.02  \n",
      "2  0.715 ± 0.026   0.595 ± 0.04  0.634 ± 0.099  0.609 ± 0.048  \n",
      "3  0.704 ± 0.028  0.582 ± 0.055  0.634 ± 0.079  0.602 ± 0.032  \n",
      "\n",
      "\n",
      "\n",
      "taiwan\n",
      "                    model            AUC    Brier Score Balanced Accuracy  \\\n",
      "0          LGBMClassifier  0.793 ± 0.001   0.15 ± 0.021     0.721 ± 0.004   \n",
      "1      LogisticRegression   0.77 ± 0.001  0.161 ± 0.025     0.709 ± 0.001   \n",
      "2           MLPClassifier  0.782 ± 0.006  0.135 ± 0.001     0.711 ± 0.004   \n",
      "3  RandomForestClassifier  0.792 ± 0.003  0.158 ± 0.022      0.72 ± 0.003   \n",
      "\n",
      "        Accuracy      Precision         Recall             F1  \n",
      "0    0.74 ± 0.02  0.449 ± 0.025  0.687 ± 0.026   0.542 ± 0.01  \n",
      "1   0.77 ± 0.004  0.488 ± 0.007  0.598 ± 0.007  0.538 ± 0.002  \n",
      "2  0.763 ± 0.011  0.476 ± 0.016  0.619 ± 0.026  0.538 ± 0.004  \n",
      "3  0.731 ± 0.025  0.439 ± 0.031    0.7 ± 0.039   0.538 ± 0.01  \n",
      "\n",
      "\n",
      "\n",
      "homecredit\n",
      "                    model            AUC    Brier Score Balanced Accuracy  \\\n",
      "0          LGBMClassifier  0.753 ± 0.001   0.13 ± 0.066     0.687 ± 0.001   \n",
      "1      LogisticRegression    0.732 ± 0.0    0.208 ± 0.0     0.671 ± 0.001   \n",
      "2           MLPClassifier  0.736 ± 0.001    0.069 ± 0.0     0.674 ± 0.001   \n",
      "3  RandomForestClassifier  0.742 ± 0.002  0.093 ± 0.051     0.677 ± 0.001   \n",
      "\n",
      "        Accuracy      Precision         Recall             F1  \n",
      "0  0.699 ± 0.014  0.165 ± 0.004  0.673 ± 0.017  0.264 ± 0.004  \n",
      "1  0.681 ± 0.013  0.154 ± 0.003   0.66 ± 0.017   0.25 ± 0.003  \n",
      "2  0.682 ± 0.009  0.155 ± 0.002  0.665 ± 0.012  0.252 ± 0.002  \n",
      "3  0.677 ± 0.015  0.155 ± 0.004  0.677 ± 0.018  0.252 ± 0.004  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in test_metrics:\n",
    "    print(dataset)\n",
    "    print(transform_to_table(test_metrics[dataset]))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_credit_experiment_fair(dataset_name, seed = 0):\n",
    "\n",
    "    # computing fairness metrics\n",
    "    path_1 = \"../results/fair_models\"\n",
    "    path_2 = \"../results/credit_models\"\n",
    "\n",
    "    metrics_folds_val = []\n",
    "    metrics_folds_test = []\n",
    "    for fold in range(10):\n",
    "        model_dict_val = {}\n",
    "        model_dict_test = {}\n",
    "        X_train, _, Y_train, X_val, _, Y_val, X_test, _, Y_test = load_split(\n",
    "            dataset_name, fold, seed\n",
    "        )\n",
    "\n",
    "        # It was necessary to compute the pipeline again due to pickle error\n",
    "        if dataset_name == \"homecredit\":\n",
    "            pipeline_preprocess = training.create_pipeline(X_train, Y_train, crit=4)\n",
    "        else:\n",
    "            pipeline_preprocess = training.create_pipeline(X_train, Y_train)\n",
    "        pipeline_preprocess.fit(X_train, Y_train)\n",
    "        X_train_preprocessed = pipeline_preprocess.transform(X_train)\n",
    "        X_val_preprocessed = pipeline_preprocess.transform(X_val)\n",
    "        A_val = X_val_preprocessed[PROTECTED_ATTRIBUTES[dataset_name] + \"_0\"]\n",
    "        X_test_preprocessed = pipeline_preprocess.transform(X_test)\n",
    "        A_test = X_test_preprocessed[PROTECTED_ATTRIBUTES[dataset_name] + \"_0\"]\n",
    "\n",
    "        models_files_1 = glob(f\"{path_1}/{dataset_name}/{fold}/*.pkl\")\n",
    "        models_files_1 = [file for file in models_files_1 if \"study\" not in file]\n",
    "        models_files_2 = glob(f\"{path_2}/{dataset_name}/{fold}/*.pkl\")\n",
    "        models_files_2 = [file for file in models_files_2 if \"study\" not in file]\n",
    "        models_files = models_files_1 + models_files_2\n",
    "\n",
    "        class Thr_helper:\n",
    "            def __init__(self, model, sensitive_features):\n",
    "                self.model = model\n",
    "                self.sensitive_features = sensitive_features\n",
    "\n",
    "            def predict(self, X):\n",
    "                return self.model.predict(\n",
    "                    X, sensitive_features=self.sensitive_features\n",
    "                )\n",
    "\n",
    "        for file in models_files:\n",
    "            if file.find(\"thr\") != -1:\n",
    "                continue\n",
    "            model = joblib.load(file)\n",
    "            model_name = file.split(\"/\")[-1].split(\".\")[0]\n",
    "            Y_train_pred = model.predict_proba(X_train)[:, 1]\n",
    "            threshold = training.ks_threshold(Y_train, Y_train_pred)\n",
    "            Y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "            Y_val_pred = (Y_val_pred > threshold).astype(int)\n",
    "            model_dict_val[model_name] = Y_val_pred\n",
    "            Y_test_pred = model.predict_proba(X_test)[:, 1]\n",
    "            Y_test_pred = (Y_test_pred > threshold).astype(int)\n",
    "            model_dict_test[model_name] = Y_test_pred\n",
    "\n",
    "        metrics_folds_val.append(\n",
    "            evaluate.get_fairness_metrics(model_dict_val, X_val, Y_val, A_val, benefit_class = 0)\n",
    "        )\n",
    "        metrics_folds_test.append(\n",
    "            evaluate.get_fairness_metrics(model_dict_test, X_test, Y_test, A_test, benefit_class = 0)\n",
    "        )\n",
    "        metrics_folds_test[-1][\"fold\"] = fold\n",
    "\n",
    "        # Threshold Optimizer needs a different procedure as it does not predict probabilities\n",
    "        for file in models_files:\n",
    "            if file.find(\"thr\") == -1:\n",
    "                continue\n",
    "\n",
    "            model = joblib.load(file)\n",
    "            model_name = file.split(\"/\")[-1].split(\".\")[0]\n",
    "            thr_opt_helper_val = Thr_helper(model, A_val)\n",
    "            Y_val_pred = thr_opt_helper_val.predict(X_val_preprocessed)\n",
    "            thr_opt_helper_test = Thr_helper(model, A_test)\n",
    "            Y_test_pred = thr_opt_helper_test.predict(X_test_preprocessed)\n",
    "            \n",
    "            model_dict_val = {model_name : Y_val_pred}\n",
    "            model_dict_test = {model_name : Y_test_pred}\n",
    "            metrics_folds_val.append(\n",
    "                evaluate.get_fairness_metrics(\n",
    "                    model_dict_val, X_val_preprocessed, Y_val, A_val, benefit_class = 0\n",
    "                )\n",
    "            )\n",
    "            metrics_folds_test.append(\n",
    "                evaluate.get_fairness_metrics(\n",
    "                    model_dict_test, X_test_preprocessed, Y_test, A_test, benefit_class = 0\n",
    "                )\n",
    "            )\n",
    "            metrics_folds_test[-1][\"fold\"] = fold\n",
    "\n",
    "\n",
    "    # this need to be evaluated separately because it uses a different set of features\n",
    "    path = \"../results/credit_models_unaware\"\n",
    "    for fold in range(10):\n",
    "        model_dict_val = {}\n",
    "        model_dict_test = {}\n",
    "        X_train, _, Y_train, X_val, _, Y_val, X_test, _, Y_test = load_split(\n",
    "            dataset_name, fold, seed, unaware = False\n",
    "        )\n",
    "\n",
    "        # It was necessary to compute the pipeline again due to pickle error\n",
    "        if dataset_name == \"homecredit\":\n",
    "            pipeline_preprocess = training.create_pipeline(X_train, Y_train, crit=4)\n",
    "        else:\n",
    "            pipeline_preprocess = training.create_pipeline(X_train, Y_train)\n",
    "        pipeline_preprocess.fit(X_train, Y_train)\n",
    "        X_val_preprocessed = pipeline_preprocess.transform(X_val)\n",
    "        A_val = X_val_preprocessed[PROTECTED_ATTRIBUTES[dataset_name] + \"_0\"]\n",
    "        X_test_preprocessed = pipeline_preprocess.transform(X_test)\n",
    "        A_test = X_test_preprocessed[PROTECTED_ATTRIBUTES[dataset_name] + \"_0\"]\n",
    "\n",
    "\n",
    "        X_train, _, Y_train, X_val, _, Y_val, X_test, _, Y_test = load_split(\n",
    "            dataset_name, fold, seed, unaware = True\n",
    "        )\n",
    "\n",
    "\n",
    "        models_files = glob(f\"{path}/{dataset_name}/{fold}/*.pkl\")\n",
    "        models_files = [file for file in models_files if \"study\" not in file]\n",
    "\n",
    "        for file in models_files:\n",
    "            model = joblib.load(file)\n",
    "            model_name = file.split(\"/\")[-1].split(\".\")[0]\n",
    "            Y_train_pred = model.predict_proba(X_train)[:, 1]\n",
    "            threshold = training.ks_threshold(Y_train, Y_train_pred)\n",
    "            Y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "            Y_val_pred = (Y_val_pred > threshold).astype(int)\n",
    "            model_dict_val[model_name+\"_unaware\"] = Y_val_pred\n",
    "            Y_test_pred = model.predict_proba(X_test)[:, 1]\n",
    "            Y_test_pred = (Y_test_pred > threshold).astype(int)\n",
    "            model_dict_test[model_name+\"_unaware\"] = Y_test_pred\n",
    "\n",
    "        metrics_folds_val.append(\n",
    "            evaluate.get_fairness_metrics(model_dict_val, X_val, Y_val, A_val, benefit_class = 0)\n",
    "        )\n",
    "        metrics_folds_test.append(\n",
    "            evaluate.get_fairness_metrics(model_dict_test, X_test, Y_test, A_test, benefit_class = 0)\n",
    "        )\n",
    "        metrics_folds_test[-1][\"fold\"] = fold\n",
    "\n",
    "    metrics_val = pd.concat(metrics_folds_val)    \n",
    "    metrics_test = pd.concat(metrics_folds_test)\n",
    "        \n",
    "    return metrics_val, metrics_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = {}\n",
    "for dataset in [\"german\", \"taiwan\", \"homecredit\"]:\n",
    "    _, t = summarize_credit_experiment_fair(dataset, seed=0)\n",
    "    test_metrics[dataset] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german\n",
      "                             model balanced_accuracy            EOD  \\\n",
      "0      DemographicParityClassifier     0.707 ± 0.015  0.076 ± 0.083   \n",
      "1       EqualOpportunityClassifier      0.71 ± 0.014  0.092 ± 0.059   \n",
      "2                FairGBMClassifier     0.638 ± 0.058   0.06 ± 0.046   \n",
      "3                   LGBMClassifier     0.632 ± 0.041    0.09 ± 0.06   \n",
      "4           LGBMClassifier_unaware     0.656 ± 0.033  0.041 ± 0.035   \n",
      "5               LogisticRegression     0.697 ± 0.024   0.193 ± 0.06   \n",
      "6       LogisticRegression_unaware     0.701 ± 0.014  0.073 ± 0.037   \n",
      "7                    MLPClassifier     0.672 ± 0.049  0.177 ± 0.169   \n",
      "8            MLPClassifier_unaware     0.696 ± 0.033  0.066 ± 0.058   \n",
      "9           RandomForestClassifier     0.672 ± 0.027   0.181 ± 0.07   \n",
      "10  RandomForestClassifier_unaware     0.688 ± 0.025   0.12 ± 0.056   \n",
      "11               rw_LGBMClassifier     0.652 ± 0.059  0.055 ± 0.042   \n",
      "12           rw_LogisticRegression      0.697 ± 0.03  0.055 ± 0.046   \n",
      "13                rw_MLPClassifier     0.699 ± 0.022  0.092 ± 0.073   \n",
      "14       rw_RandomForestClassifier     0.675 ± 0.027  0.072 ± 0.045   \n",
      "15              thr_LGBMClassifier     0.646 ± 0.025  0.048 ± 0.028   \n",
      "16          thr_LogisticRegression     0.689 ± 0.022  0.043 ± 0.019   \n",
      "17               thr_MLPClassifier     0.699 ± 0.051  0.054 ± 0.045   \n",
      "18      thr_RandomForestClassifier     0.684 ± 0.031  0.074 ± 0.057   \n",
      "\n",
      "              DPD           APVD  \n",
      "0   0.059 ± 0.058  0.084 ± 0.034  \n",
      "1    0.05 ± 0.045  0.086 ± 0.025  \n",
      "2   0.028 ± 0.019  0.096 ± 0.019  \n",
      "3   0.066 ± 0.037   0.13 ± 0.031  \n",
      "4   0.048 ± 0.025  0.103 ± 0.041  \n",
      "5   0.124 ± 0.055  0.137 ± 0.026  \n",
      "6    0.041 ± 0.03  0.094 ± 0.028  \n",
      "7   0.145 ± 0.147   0.132 ± 0.04  \n",
      "8   0.086 ± 0.047  0.088 ± 0.025  \n",
      "9   0.103 ± 0.065  0.132 ± 0.024  \n",
      "10  0.067 ± 0.044  0.112 ± 0.018  \n",
      "11   0.04 ± 0.038    0.1 ± 0.019  \n",
      "12   0.038 ± 0.04  0.088 ± 0.019  \n",
      "13  0.079 ± 0.052  0.106 ± 0.025  \n",
      "14   0.04 ± 0.029  0.102 ± 0.019  \n",
      "15  0.073 ± 0.053   0.11 ± 0.034  \n",
      "16  0.088 ± 0.029  0.056 ± 0.012  \n",
      "17  0.121 ± 0.042  0.058 ± 0.025  \n",
      "18  0.039 ± 0.029  0.096 ± 0.024  \n",
      "\n",
      "\n",
      "\n",
      "taiwan\n",
      "                             model balanced_accuracy            EOD  \\\n",
      "0      DemographicParityClassifier     0.708 ± 0.003  0.036 ± 0.021   \n",
      "1       EqualOpportunityClassifier     0.707 ± 0.002  0.036 ± 0.006   \n",
      "2                FairGBMClassifier      0.72 ± 0.004  0.029 ± 0.011   \n",
      "3                   LGBMClassifier     0.721 ± 0.002  0.049 ± 0.007   \n",
      "4           LGBMClassifier_unaware     0.721 ± 0.004  0.023 ± 0.006   \n",
      "5               LogisticRegression     0.709 ± 0.001   0.051 ± 0.02   \n",
      "6       LogisticRegression_unaware     0.709 ± 0.001  0.018 ± 0.002   \n",
      "7                    MLPClassifier     0.713 ± 0.003  0.074 ± 0.016   \n",
      "8            MLPClassifier_unaware     0.711 ± 0.004  0.026 ± 0.005   \n",
      "9           RandomForestClassifier     0.721 ± 0.004  0.032 ± 0.007   \n",
      "10  RandomForestClassifier_unaware      0.72 ± 0.003   0.02 ± 0.006   \n",
      "11               rw_LGBMClassifier     0.721 ± 0.004  0.011 ± 0.007   \n",
      "12           rw_LogisticRegression     0.709 ± 0.002  0.007 ± 0.007   \n",
      "13                rw_MLPClassifier      0.71 ± 0.002  0.012 ± 0.008   \n",
      "14       rw_RandomForestClassifier     0.718 ± 0.004  0.017 ± 0.006   \n",
      "15              thr_LGBMClassifier     0.719 ± 0.003  0.007 ± 0.009   \n",
      "16          thr_LogisticRegression     0.709 ± 0.001  0.008 ± 0.005   \n",
      "17               thr_MLPClassifier     0.711 ± 0.002  0.006 ± 0.005   \n",
      "18      thr_RandomForestClassifier      0.72 ± 0.002  0.013 ± 0.007   \n",
      "\n",
      "              DPD           APVD  \n",
      "0   0.063 ± 0.021   0.031 ± 0.01  \n",
      "1   0.062 ± 0.005   0.03 ± 0.003  \n",
      "2    0.053 ± 0.01  0.033 ± 0.004  \n",
      "3   0.072 ± 0.007  0.025 ± 0.003  \n",
      "4   0.045 ± 0.006  0.036 ± 0.002  \n",
      "5   0.078 ± 0.019  0.022 ± 0.009  \n",
      "6   0.044 ± 0.002   0.04 ± 0.001  \n",
      "7   0.099 ± 0.015  0.013 ± 0.005  \n",
      "8    0.05 ± 0.004  0.035 ± 0.003  \n",
      "9   0.052 ± 0.005  0.033 ± 0.002  \n",
      "10  0.041 ± 0.006  0.037 ± 0.003  \n",
      "11  0.034 ± 0.009  0.041 ± 0.004  \n",
      "12  0.031 ± 0.009  0.047 ± 0.005  \n",
      "13  0.035 ± 0.009  0.043 ± 0.005  \n",
      "14  0.037 ± 0.005  0.038 ± 0.002  \n",
      "15  0.029 ± 0.009  0.043 ± 0.004  \n",
      "16  0.019 ± 0.007  0.053 ± 0.003  \n",
      "17  0.026 ± 0.008  0.048 ± 0.004  \n",
      "18  0.032 ± 0.008  0.041 ± 0.005  \n",
      "\n",
      "\n",
      "\n",
      "homecredit\n",
      "                             model balanced_accuracy            EOD  \\\n",
      "0                FairGBMClassifier     0.683 ± 0.003  0.087 ± 0.009   \n",
      "1                   LGBMClassifier     0.688 ± 0.002  0.153 ± 0.003   \n",
      "2           LGBMClassifier_unaware     0.687 ± 0.001   0.07 ± 0.003   \n",
      "3               LogisticRegression       0.675 ± 0.0  0.174 ± 0.003   \n",
      "4       LogisticRegression_unaware     0.671 ± 0.001  0.036 ± 0.001   \n",
      "5                    MLPClassifier     0.679 ± 0.001  0.168 ± 0.007   \n",
      "6            MLPClassifier_unaware     0.674 ± 0.001  0.043 ± 0.002   \n",
      "7           RandomForestClassifier     0.679 ± 0.002  0.153 ± 0.011   \n",
      "8   RandomForestClassifier_unaware     0.677 ± 0.001  0.077 ± 0.002   \n",
      "9                rw_LGBMClassifier     0.686 ± 0.002  0.015 ± 0.006   \n",
      "10           rw_LogisticRegression     0.671 ± 0.001  0.007 ± 0.002   \n",
      "11                rw_MLPClassifier     0.673 ± 0.002   0.01 ± 0.003   \n",
      "12       rw_RandomForestClassifier     0.676 ± 0.001  0.047 ± 0.004   \n",
      "13              thr_LGBMClassifier     0.685 ± 0.001  0.009 ± 0.007   \n",
      "14          thr_LogisticRegression     0.671 ± 0.001  0.015 ± 0.002   \n",
      "15               thr_MLPClassifier     0.675 ± 0.001  0.007 ± 0.002   \n",
      "16      thr_RandomForestClassifier     0.675 ± 0.001  0.016 ± 0.008   \n",
      "\n",
      "              DPD           APVD  \n",
      "0   0.097 ± 0.009  0.021 ± 0.002  \n",
      "1   0.162 ± 0.003    0.011 ± 0.0  \n",
      "2    0.08 ± 0.003  0.023 ± 0.001  \n",
      "3   0.182 ± 0.002     0.01 ± 0.0  \n",
      "4   0.045 ± 0.001    0.028 ± 0.0  \n",
      "5   0.178 ± 0.007   0.01 ± 0.001  \n",
      "6   0.053 ± 0.002    0.027 ± 0.0  \n",
      "7   0.162 ± 0.012  0.012 ± 0.002  \n",
      "8   0.086 ± 0.002    0.022 ± 0.0  \n",
      "9   0.026 ± 0.006  0.032 ± 0.001  \n",
      "10  0.015 ± 0.001    0.032 ± 0.0  \n",
      "11   0.02 ± 0.003  0.032 ± 0.001  \n",
      "12  0.056 ± 0.003  0.026 ± 0.001  \n",
      "13  0.019 ± 0.007  0.033 ± 0.002  \n",
      "14  0.023 ± 0.002    0.031 ± 0.0  \n",
      "15  0.017 ± 0.002  0.033 ± 0.001  \n",
      "16  0.025 ± 0.007  0.031 ± 0.001  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in test_metrics:\n",
    "    print(dataset)\n",
    "    print(transform_to_table(test_metrics[dataset][[\"model\", \"balanced_accuracy\", \"EOD\", \"DPD\", \"APVD\"]]))\n",
    "    print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
