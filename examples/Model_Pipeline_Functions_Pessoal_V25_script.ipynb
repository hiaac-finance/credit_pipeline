{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282652\n",
      "df_a : (5281, 14)\n",
      "df_r : (56991, 6)\n",
      "df_a : (5281, 14)\n",
      "df_r : (56991, 13)\n",
      "df_a : (5281, 14)\n",
      "df_r : (56991, 13)\n",
      "X_train : (2349, 12)\n",
      "X_val : (1008, 12)\n",
      "X_test : (1924, 12)\n",
      "y_train : (2349,)\n",
      "y_val : (1008,)\n",
      "y_test : (1924,)\n",
      "R_train : (31331, 12)\n",
      "R_val : (13428, 12)\n",
      "R_test : (12232, 12)\n"
     ]
    }
   ],
   "source": [
    "#@title **Location** of the dataset\n",
    "path =  \"../data/LendingClub/\"\n",
    "process_path = \"../data/ProcessedData/\"\n",
    "save_path = \"../tests/\"\n",
    "ri_datasets_path = \"../data/riData/\"\n",
    "backup_image_folder = \"../../backup/Images/\"\n",
    "\n",
    " \n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import secrets\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from lightgbm import LGBMClassifier\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import (roc_auc_score)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import r_regression\n",
    "\n",
    "\n",
    " \n",
    "from sklearn.metrics import (accuracy_score, balanced_accuracy_score,\n",
    "                            f1_score, precision_score, recall_score,\n",
    "                            roc_auc_score, roc_curve)\n",
    "\n",
    " \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "\n",
    " \n",
    "import credit_pipeline.data_exploration as dex\n",
    "import credit_pipeline.training as tr\n",
    "import credit_pipeline.reject_inference as ri\n",
    "import credit_pipeline.evaluate as ev\n",
    "\n",
    "from submodules.topsis_python import topsis as top\n",
    "\n",
    "\n",
    "#ARGs and constants\n",
    "parser = argparse.ArgumentParser(description='Simple Script')\n",
    "parser.add_argument('-ar', '--ar_range', type=int, nargs=2, default=[0, 100], help='Low and High AR value', metavar=('LOW_AR', 'HIGH_AR'))\n",
    "parser.add_argument('-wt', '--weights', type=int, nargs=2, default=[1, 1], help='weights of metrics for Topsis', metavar=('Weight_AUC, Weight_Kickout'))\n",
    "parser.add_argument('--seed', type=int, default=302461, help='Seed number')\n",
    "parser.add_argument('-y', '--year', type=int, default=2009, help='Year')\n",
    "parser.add_argument('-t', '--threshold', type=float, default=0.5, help='Threshold value')\n",
    "parser.add_argument('-p', '--percent_bad', type=float, default=0.2, help='Percentage bad added')\n",
    "parser.add_argument('-ut', '--use_test', action='store_true', help='Use test set to evaluate')\n",
    "parser.add_argument('-tri', '--train_ri', action='store_true', default=True, help='Train others RI models')\n",
    "parser.add_argument('-re', '--reuse_exec', action='store_true', default=True, help='Reuse trained models')\n",
    "parser.add_argument('-tn', '--train_tn', action='store_true', default=True, help='Train Trusted Non-Outliers models')\n",
    "args = parser.parse_args({})\n",
    "\n",
    "#Accept rate\n",
    "if args.ar_range:\n",
    "    low_AR, high_AR = args.ar_range\n",
    "\n",
    "#Weights\n",
    "if args.weights:\n",
    "    Weight_AUC, Weight_Kickout = args.weights\n",
    "\n",
    "#TopSis\n",
    "weights = [Weight_AUC, Weight_Kickout]\n",
    "criterias = np.array([True, True])\n",
    "\n",
    "\n",
    "threshold = args.threshold\n",
    "\n",
    "\n",
    "#Set seed\n",
    "if args.seed:\n",
    "    seed_number = args.seed\n",
    "else:\n",
    "    seed_number = secrets.randbelow(1_000_000)\n",
    "    while seed_number <100:\n",
    "        seed_number = secrets.randbelow(1_000_000)\n",
    "print(seed_number)\n",
    "main_seed = seed_number\n",
    "\n",
    "\n",
    "logpath = Path(os.path.join(ri_datasets_path,f'LC_py/log_{main_seed}'))\n",
    "logpath.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logging.getLogger().handlers = []\n",
    "# Configure logging to file\n",
    "logging.basicConfig(filename=logpath, \n",
    "                    filemode='w',  # Overwrite the file each time the application runs\n",
    "                    level=logging.DEBUG,  # Capture all levels of logging\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',  # Include timestamp, log level, and message\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')  # Format for the timestamp\n",
    "\n",
    "\n",
    "logging.debug(logpath)\n",
    "\n",
    "#Read Dataset\n",
    "    \n",
    "#Accepts\n",
    "\n",
    "la = [\"issue_d\", \"loan_amnt\", \"funded_amnt\", \"funded_amnt_inv\", \"term\", \"int_rate\"]\n",
    "lb = [\"installment\", \"emp_length\", \"annual_inc\", \"verification_status\", \"loan_status\", \n",
    "    \"purpose\", \"addr_state\", \"dti\", \"delinq_2yrs\"]\n",
    "lc = [\"inq_last_6mths\", \"open_acc\", \"home_ownership\", \"revol_bal\", \"revol_util\",\n",
    "    \"total_acc\", \"total_pymnt\", \"total_rec_prncp\", \"total_rec_int\", \"total_pymnt_inv\",\n",
    "        \"last_pymnt_amnt\", \"last_fico_range_high\", \"last_fico_range_low\"]\n",
    "\n",
    "selected_columns_a = la+lb+lc\n",
    "# Define the chunk size for reading the CSV file\n",
    "chunksize = 100000  # Adjust this value based on your requirements\n",
    "# Initialize an empty list to store filtered chunks\n",
    "filtered_chunks = []\n",
    "# Read the CSV file in chunks based on the defined chunk size\n",
    "for chunk in pd.read_csv(path+'accepted_2007_to_2018Q4.csv', chunksize=chunksize, usecols=selected_columns_a):\n",
    "    # Filter the current chunk based on the criteria\n",
    "    filtered_chunk = chunk[chunk['issue_d'].str.contains(str(args.year), na=False)]\n",
    "    # Append the filtered chunk to the list\n",
    "    filtered_chunks.append(filtered_chunk)\n",
    "# Concatenate all filtered chunks into a single DataFrame\n",
    "df_a = pd.concat(filtered_chunks)\n",
    "logging.debug(f'Accepts read with shape: {df_a.shape}')\n",
    "# Now filtered_df contains only the rows that match the specified criteria\n",
    "logging.debug(f'Selected columns: {selected_columns_a}')\n",
    "    \n",
    "#Rejects\n",
    "selected_columns_r = [\"Application Date\", \"Debt-To-Income Ratio\",\"State\", \"Risk_Score\", \"Amount Requested\", \"Employment Length\"]\n",
    "# Define the chunk size for reading the CSV file\n",
    "chunksize = 100000  # Adjust this value based on your requirements\n",
    "# Initialize an empty list to store filtered chunks\n",
    "filtered_chunks = []\n",
    "# Read the CSV file in chunks based on the defined chunk size\n",
    "for chunk in pd.read_csv(path+'rejected_2007_to_2018Q4.csv', chunksize=chunksize, usecols=selected_columns_r):\n",
    "    # Filter the current chunk based on the criteria\n",
    "    chunk[\"Application Date\"] = chunk[\"Application Date\"].astype(str)\n",
    "    filtered_chunk = chunk[chunk[\"Application Date\"].str.contains(str(args.year), na=False)]\n",
    "    # filtered_chunk = filtered_chunk[~filtered_chunk[\"Application Date\"].str.contains(\"2013-10|2013-11|2013-12\", na=False)]\n",
    "    # Append the filtered chunk to the list\n",
    "    filtered_chunks.append(filtered_chunk)\n",
    "# Concatenate all filtered chunks into a single DataFrame\n",
    "df_r = pd.concat(filtered_chunks)\n",
    "# Now filtered_df contains only the rows that match the specified criteria\n",
    "logging.debug(f'Rejects read with shape: {df_r.shape}')\n",
    "# Log the rejected columns\n",
    "logging.debug(f'Rejected columns: {df_r.columns.tolist()}')\n",
    "    \n",
    "#rejected fix names\n",
    "df_r[\"emp_length\"] = df_r[\"Employment Length\"]\n",
    "df_r[\"addr_state\"] = df_r[\"State\"]\n",
    "df_r[\"dti\"] = df_r[\"Debt-To-Income Ratio\"]\n",
    "df_r[\"dti\"] = pd.to_numeric(df_r['dti'].str.replace('%', ''))\n",
    "df_r[\"loan_amnt\"] = df_r[\"Amount Requested\"]\n",
    "df_r[\"risk_score\"] = df_r[\"Risk_Score\"]\n",
    "df_r[\"issue_d\"] = df_r[\"Application Date\"]\n",
    "\n",
    "#accepted fix names\n",
    "df_a[\"risk_score\"] = df_a.loc[:,[\"last_fico_range_high\",\"last_fico_range_low\"]].mean(axis=1)\n",
    "df_a[\"target\"] = np.where((df_a.loan_status == 'Current') |\n",
    "                        (df_a.loan_status == 'Fully Paid') |\n",
    "                        (df_a.loan_status== \"Issued\") |\n",
    "                        (df_a.loan_status == 'Does not meet the credit policy. Status:Fully Paid'), 0, 1)\n",
    "\n",
    "\n",
    "    \n",
    "for c in [\"Amount Requested\", \"Employment Length\", \"State\",\n",
    "                \"Debt-To-Income Ratio\", \"Amount Requested\",\"Risk_Score\", \"Application Date\"]:\n",
    "    try:\n",
    "        df_r = df_r.drop(c, axis = 1)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "for c in ['last_fico_range_high', 'last_fico_range_low', 'loan_status']:\n",
    "    try:\n",
    "        df_a = df_a.drop(c, axis = 1)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "\n",
    "# columns based on Shih et al. (2022)\n",
    "r_cols = df_r.columns.to_list()\n",
    "pearson_a = ['int_rate', 'dti', 'delinq_2yrs', 'emp_length', 'annual_inc', 'inq_last_6mths', 'term',\n",
    "'home_ownership','revol_util', 'risk_score', 'target', 'issue_d']\n",
    "union_list = r_cols.copy()\n",
    "for item in pearson_a:\n",
    "    if item not in union_list:\n",
    "        union_list.append(item)\n",
    "# Now union_list contains all elements from r_cols first, followed by those unique to pearson_a\n",
    "df_a = df_a.loc[:, union_list]\n",
    "        \n",
    "logging.debug(\"Now union_list contains all elements from r_cols first, followed by those unique to pearson_a\")\n",
    "\n",
    "    \n",
    "#Fix dtype of variable emp_length (Object -> number)\n",
    "try:\n",
    "    df_a['emp_length'] = df_a['emp_length'].map(lambda x: \"0\" if x == '< 1 year' else x)\n",
    "    df_a['emp_length'] = df_a['emp_length'].map(lambda x : int(re.search(r'\\d+', x).group()), na_action='ignore')\n",
    "\n",
    "    df_r['emp_length'] = df_r['emp_length'].map(lambda x: \"0\" if x == '< 1 year' else x)\n",
    "    df_r['emp_length'] = df_r['emp_length'].map(lambda x : int(re.search(r'\\d+', x).group()), na_action='ignore')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "try:\n",
    "    df_a['term'] = df_a['term'].map(lambda x : int(re.search(r'\\d+', x).group()))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "    \n",
    "#add missing columns to df_r\n",
    "input_columns = df_a.columns.difference(df_r.columns).to_list()\n",
    "input_columns.remove('target')\n",
    "\n",
    "for col in input_columns:\n",
    "    df_r.insert(df_r.columns.shape[0], col, np.nan)\n",
    "\n",
    "logging.debug('Data preprocessing complete!')\n",
    "\n",
    "    \n",
    "params_dict = ri.params_dict\n",
    "\n",
    "    \n",
    "params_dict['LightGBM_2'] = {'boosting_type': 'gbdt', 'class_weight': None,\n",
    "            'colsample_bytree': 0.22534977954592625, 'importance_type': 'split',\n",
    "            'learning_rate': 0.052227873762946964, 'max_depth': 5,\n",
    "            'min_child_samples': 26, 'min_child_weight': 0.001,\n",
    "            'min_split_gain': 0.0, 'n_estimators': 159, 'n_jobs': -1,\n",
    "            'num_leaves': 12, 'objective': None, 'random_state': seed_number,\n",
    "            'reg_alpha': 0.7438345471808012, 'reg_lambda': 0.46164693905368515,\n",
    "                'verbose': -1, 'subsample': 0.8896599304061413,\n",
    "            'subsample_for_bin': 200000, 'subsample_freq': 0,\n",
    "            'is_unbalance': True}\n",
    "    \n",
    "try:\n",
    "    train_rej = df_r[~df_r['issue_d'].str.contains(f\"{args.year}-10|{args.year}-11|{args.year}-12\", na=False)]\n",
    "    train_acp = df_a[~df_a['issue_d'].str.contains(f\"Oct-{args.year}|Nov-{args.year}|Dec-{args.year}\", na=False)]\n",
    "\n",
    "    test_rej = df_r[df_r['issue_d'].str.contains(f\"{args.year}-10|{args.year}-11|{args.year}-12\", na=False)]\n",
    "    test_acp = df_a[df_a['issue_d'].str.contains(f\"Oct-{args.year}|Nov-{args.year}|Dec-{args.year}\", na=False)]\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "train_r, train_a, test_r, test_a = train_rej.copy(), train_acp.copy(), test_rej.copy(), test_acp.copy()\n",
    "\n",
    "for df in [train_r, train_a, test_r, test_a]:\n",
    "    try:\n",
    "        df.drop('issue_d', axis = 1, inplace=True)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "logging.debug(f'Train-Test split done')\n",
    "\n",
    "    \n",
    "X_train = train_a.loc[:, train_a.columns != \"target\"]\n",
    "y = train_a[\"target\"]\n",
    "X_test = test_a.loc[:, test_a.columns != \"target\"]\n",
    "y_test = test_a[\"target\"]\n",
    "\n",
    "    \n",
    "knn_inputer = tr.create_pipeline(X_train,y, None, do_EBE=True, crit = 0, do_KNN=True)\n",
    "knn_inputer.fit(X_train,y)\n",
    "X_train_knn = knn_inputer[:-3].transform(X_train)\n",
    "X_test = knn_inputer[:-3].transform(X_test)\n",
    "R_train_knn = knn_inputer[:-3].transform(train_r)\n",
    "R_test = knn_inputer[:-3].transform(test_r)\n",
    "logging.debug(f'KNN input done')\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_knn, y, test_size=0.3, random_state=main_seed, shuffle=True)\n",
    "R_train, R_val = train_test_split(\n",
    "    R_train_knn, test_size=0.3, random_state=main_seed, shuffle=True)\n",
    "logging.debug(f'Train-Val split done')\n",
    "\n",
    "\n",
    "if args.use_test:\n",
    "    X_eval = X_test.copy()\n",
    "    y_eval = y_test.copy()\n",
    "    R_eval = R_test.copy()\n",
    "else:\n",
    "    X_eval = X_val.copy()\n",
    "    y_eval = y_val.copy()\n",
    "    R_eval = R_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'train_ri'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m models_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBM\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m benchmark\n\u001b[1;32m     10\u001b[0m logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbenchmark fitted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnew_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_ri\u001b[49m:\n\u001b[1;32m     13\u001b[0m     models_dict\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m     14\u001b[0m         ri\u001b[38;5;241m.\u001b[39maugmentation_with_soft_cutoff(X_train, y_train, R_train, seed \u001b[38;5;241m=\u001b[39m seed_number))\n\u001b[1;32m     15\u001b[0m     logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maugmentation_with_soft_cutoff fitted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'train_ri'"
     ]
    }
   ],
   "source": [
    "models_dict = {}\n",
    "\n",
    "# Acp classifier benchmark\n",
    "benchmark = tr.create_pipeline(X_train, y_train, LGBMClassifier(**params_dict['LightGBM_2']))\n",
    "benchmark.fit(X_train, y_train)\n",
    "\n",
    "#RI models\n",
    "models_dict['BM'] = benchmark\n",
    "\n",
    "logging.debug(f'benchmark fitted')\n",
    "\n",
    "if args.train_ri:\n",
    "    models_dict.update(\n",
    "        ri.augmentation_with_soft_cutoff(X_train, y_train, R_train, seed = seed_number))\n",
    "    logging.debug(f'augmentation_with_soft_cutoff fitted')\n",
    "    models_dict.update(\n",
    "        ri.augmentation(X_train, y_train, R_train, mode='up', seed = seed_number))\n",
    "    logging.debug(f'augmentation upward fitted')\n",
    "    models_dict.update(\n",
    "        ri.fuzzy_augmentation(X_train, y_train, R_train, seed = seed_number))\n",
    "    logging.debug(f'fuzzy_augmentation fitted')\n",
    "    models_dict.update(\n",
    "        ri.extrapolation(X_train, y_train, R_train, seed = seed_number))\n",
    "    logging.debug(f'extrapolation fitted')\n",
    "    models_dict.update(\n",
    "        ri.parcelling(X_train, y_train, R_train, seed = seed_number))\n",
    "    logging.debug(f'parcelling fitted')\n",
    "    models_dict.update(\n",
    "        ri.label_spreading(X_train, y_train, R_train, seed = seed_number))\n",
    "    logging.debug(f'label_spreading fitted')\n",
    "\n",
    "if args.train_tn:\n",
    "    filepath_ex = Path(os.path.join(ri_datasets_path,f'TN-{seed_number}.joblib'))\n",
    "    filepath_ls = Path(os.path.join(ri_datasets_path,f'TN+-{seed_number}.joblib'))\n",
    "\n",
    "    if filepath_ex.exists() and args.reuse_exec:\n",
    "        models_ex = joblib.load(filepath_ex)\n",
    "        logging.debug(f'TN loaded')\n",
    "    else:\n",
    "        ri.trusted_non_outliers(X_train=X_train, y_train=y_train, X_unl=R_train,\n",
    "                                        X_val=X_val, y_val=y_val, iterations=50, p=args.percent_bad, acp_rate=0.5,\n",
    "                                        technique='extrapolation', seed=seed_number, output=-1)\n",
    "        logging.debug(f'TN fitted')\n",
    "        models_ls = joblib.load(filepath_ls)\n",
    "    if filepath_ls.exists() and args.reuse_exec:\n",
    "        models_ls = joblib.load(filepath_ls)\n",
    "        logging.debug(f'TN+ loaded')\n",
    "    else:\n",
    "        ri.trusted_non_outliers(X_train=X_train, y_train=y_train, X_unl=R_train,\n",
    "                                        X_val=X_val, y_val=y_val, iterations=50, p=args.percent_bad, acp_rate=0.5,\n",
    "                                        technique='LS', seed=seed_number, output=-1)\n",
    "        logging.debug(f'TN+ fitted')\n",
    "\n",
    "# Initialize a dictionary to hold all the basic metrics\n",
    "df_metrics = ri.get_metrics_RI(models_dict, X_eval, y_eval, X_unl=R_eval)\n",
    "if args.use_test:\n",
    "    filepath = Path(os.path.join(ri_datasets_path, f'metrics_bm_test/Exp_{main_seed}.csv'))\n",
    "else:\n",
    "    filepath = Path(os.path.join(ri_datasets_path, f'metrics_bm_val/Exp_{main_seed}.csv'))\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_metrics.round(4).to_csv(filepath, index=True)\n",
    "\n",
    "# Store kickout values for all ARs\n",
    "# Initialize a dictionary to hold the kickout values for each model\n",
    "kick_by_model_dict = {}\n",
    "# Iterate over each model in the models_dict\n",
    "\n",
    "for mname, mmodel in models_dict.items():\n",
    "    # Calculate the pre-kickout probabilities for the benchmark model and the current model\n",
    "    p_acp, p_all = ri.pre_kickout(models_dict['BM'], models_dict[mname], X_eval, R_eval)    \n",
    "    # Initialize a dictionary to hold the kickout values for each AR\n",
    "    ar_dict = {}\n",
    "    # Iterate over the range of low_AR to high_AR\n",
    "    for a in range(low_AR, high_AR):\n",
    "        # Calculate the AR value\n",
    "        AR = a/100\n",
    "        # Calculate the kickout value using the faster_kickout function\n",
    "        kick_value = ri.faster_kickout(y_eval, p_acp, p_all, acp_rate=AR)[0]\n",
    "        # Store the kickout value in the ar_dict\n",
    "        ar_dict[a] = kick_value\n",
    "\n",
    "    # Store the ar_dict in the kick_by_model_dict for the current model\n",
    "    kick_by_model_dict[mname] = ar_dict\n",
    "\n",
    "df_kick_by_model = pd.DataFrame(kick_by_model_dict)\n",
    "if args.use_test:\n",
    "    filepath = Path(os.path.join(ri_datasets_path,f'df_kick_by_model_test/Exp_{main_seed}.csv'))\n",
    "else:\n",
    "    filepath = Path(os.path.join(ri_datasets_path,f'df_kick_by_model_val/Exp_{main_seed}.csv'))\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_kick_by_model.round(4).to_csv(filepath, index=True)\n",
    "\n",
    "\n",
    "if args.train_tn:\n",
    "    models_ex = joblib.load(filepath_ex)\n",
    "    models_ls = joblib.load(filepath_ls)\n",
    "\n",
    "    kar_ex = ri.calculate_kickout_by_ar(models_ex, X_eval, y_eval, R_eval, low_AR, high_AR)\n",
    "    kar_ls = ri.calculate_kickout_by_ar(models_ls, X_eval, y_eval, R_eval, low_AR, high_AR)\n",
    "    \n",
    "    if args.use_test:\n",
    "        filepath_ex = Path(os.path.join(ri_datasets_path, f'kar_ex/test/Exp_{main_seed}.csv'))\n",
    "        filepath_ls = Path(os.path.join(ri_datasets_path, f'kar_ls/test/Exp_{main_seed}.csv'))\n",
    "    else:\n",
    "        filepath_ex = Path(os.path.join(ri_datasets_path, f'kar_ex/val/Exp_{main_seed}.csv'))\n",
    "        filepath_ls = Path(os.path.join(ri_datasets_path, f'kar_ls/val/Exp_{main_seed}.csv'))\n",
    "\n",
    "    filepath_ex.parent.mkdir(parents=True, exist_ok=True)\n",
    "    kar_ex.round(4).to_csv(filepath_ex, index=True)\n",
    "    \n",
    "    filepath_ls.parent.mkdir(parents=True, exist_ok=True)\n",
    "    kar_ls.round(4).to_csv(filepath_ls, index=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "h-h3CuT8QlAM",
    "tAVCg2OVBYja",
    "dsDca864gWOL"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
